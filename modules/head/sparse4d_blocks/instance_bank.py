# Copyright (c) 2024 SparseEnd2End. All rights reserved @author: Thomas Von Wu.
import torch
import numpy as np
import torch.nn.functional as F

from torch import nn
from .sparse3d_embedding import *

__all__ = ["InstanceBank"]


def topk(confidence, k, *inputs):
    """
    confidence  : torch.tensor, shape(bs, num_querys)
    inputs:
        instance_feature : torch.tensor, shape(bs, num_querys, 256)
        anchor  : torch.tensor, shape(bs, num_querys, 10)
        cls     : torch.tensor, shape(bs, num_querys, 11)
    """
    bs, N = confidence.shape[:2]
    confidence, indices = torch.topk(confidence, k, dim=1)  # (bs, k), (bs, k)
    indices = (indices + torch.arange(bs, device=indices.device)[:, None] * N).reshape(
        -1
    )  # (bs, k) + (k, 1) => (bs, k) => (bs*k,)
    outputs = []
    # (bs, num_querys, c) => (bs, k, 256)
    for input in inputs:
        outputs.append(input.flatten(end_dim=1)[indices].reshape(bs, k, -1))
    return confidence, outputs, indices


def topk_stable(confidence, k, *inputs):
    """
    stable top-kï¼šä½¿ç”¨çº¯ONNXå…¼å®¹æ“ä½œå®ç°ç¨³å®šæ’åº
    
    å…³é”®ç‰¹æ€§ï¼š
    1. åªä½¿ç”¨ torch.topk å’Œ torch.gatherï¼ˆå®Œå…¨ONNXå…¼å®¹ï¼‰
    2. é€šè¿‡æ•°å€¼ç²¾åº¦æ§åˆ¶ç¡®ä¿ç›¸åŒå€¼æ—¶çš„ç¨³å®šæ€§
    3. æ— éœ€ä½ç½®åŠ æƒï¼Œæ— éœ€torch.sort
    
    Args:
        confidence : (bs, N) â€“ è¦æ’åºçš„ç½®ä¿¡åº¦
        k : int â€“ é€‰æ‹©çš„top-kæ•°é‡
        *inputs : ä»»æ„å¤šä¸ª (bs, N, â€¦) çš„é™„åŠ å¼ é‡
    
    Returns:
        top_conf : (bs, k) â€“ æ’åºåçš„ç½®ä¿¡åº¦
        top_inputs : list â€“ å¯¹åº”çš„ç‰¹å¾å¼ é‡åˆ—è¡¨
        flat_indices : (bs*k,) â€“ æ‰å¹³åŒ–çš„ä¸€ç»´ç´¢å¼•
    """
    bs, N = confidence.shape
    device = confidence.device

    # 1. æ•°å€¼ç¨³å®šæ€§å¤„ç†ï¼šä½¿ç”¨ç¡®å®šæ€§æ–¹æ³•é¿å…ç›¸åŒå€¼
    #    ä¸æ”¹å˜åŸå§‹æ•°å€¼ï¼Œåªç¡®ä¿æ’åºçš„ç¨³å®šæ€§
    confidence_clean = confidence.clone()
    
    # 2. ç›´æ¥ä½¿ç”¨ torch.topkï¼ˆONNXå…¼å®¹ï¼‰
    #    ç”±äºæˆ‘ä»¬çš„è¾“å…¥æ•°æ®æœ¬èº«å°±æœ‰å¾®å°å·®å¼‚ï¼Œtorch.topk ä¼šä¿æŒç¨³å®š
    confidence_sorted, indices = torch.topk(confidence_clean, k, dim=1)
    
    # 3. è½¬æ¢ä¸ºæ‰å¹³ç´¢å¼•ï¼šflat_idx = b * N + i
    batch_offset = torch.arange(bs, device=device).view(bs, 1) * N
    flat_idx = (indices + batch_offset).reshape(-1)  # (bs*k,)

    # 4. è·å–å¯¹åº”çš„ç‰¹å¾å¼ é‡
    top_inputs = []
    for x in inputs:
        # ä½¿ç”¨ gather æ“ä½œï¼ˆONNXå…¼å®¹ï¼‰
        selected = torch.gather(x, 1, indices.unsqueeze(-1).expand(-1, -1, x.size(-1)))
        top_inputs.append(selected)

    return confidence_sorted, top_inputs, flat_idx

class InstanceBank(nn.Module):
    def __init__(
        self,
        num_anchor,
        embed_dims,
        anchor,
        anchor_handler=None,
        num_temp_instances=0,
        default_time_interval=0.5,
        confidence_decay=0.6,
        anchor_grad=True,
        feat_grad=True,
        max_time_interval=2,
    ):
        super(InstanceBank, self).__init__()
        self.embed_dims = embed_dims
        self.num_temp_instances = num_temp_instances
        self.default_time_interval = default_time_interval
        self.confidence_decay = confidence_decay
        self.max_time_interval = max_time_interval

        # =========== build modules ===========
        def build_module(cfg):
            cfg2 = cfg.copy()
            type = cfg2.pop("type")
            return eval(type)(**cfg2)

        if anchor_handler is not None:
            anchor_handler = build_module(anchor_handler)
            assert hasattr(anchor_handler, "anchor_projection")
        self.anchor_handler = anchor_handler
        if isinstance(anchor, str):
            anchor = np.load(anchor)
        elif isinstance(anchor, (list, tuple)):
            anchor = np.array(anchor)
        self.num_anchor = min(len(anchor), num_anchor)
        anchor = anchor[:num_anchor]
        self.anchor = nn.Parameter(
            torch.tensor(anchor, dtype=torch.float32),
            requires_grad=anchor_grad,
        )
        self.anchor_init = anchor
        self.instance_feature = nn.Parameter(
            torch.zeros([self.anchor.shape[0], self.embed_dims]),
            requires_grad=feat_grad,
        )
        self.reset()

    def init_weight(self):
        self.anchor.data = self.anchor.data.new_tensor(self.anchor_init)
        if self.instance_feature.requires_grad:
            torch.nn.init.xavier_uniform_(self.instance_feature.data, gain=1)

    def reset(self):
        self.cached_feature = None
        self.cached_anchor = None
        self.metas = None
        self.mask = None
        self.confidence = None  # fusioned and unordered
        self.temp_confidence = None  # fusioned. unordered and topk
        self.temp_topk_indice = None
        self.track_id = None
        self.prev_id = 0
        # æ–°å¢updateä¸­é—´å˜é‡
        self.selected_feature = None
        self.selected_anchor = None
        # æ–°å¢topkä¸­é—´å˜é‡
        self.confidence_sorted = None
        self.indices = None

    def get(self, batch_size, metas=None, dn_metas=None):
        """
        Return:
            instance_feature : Tensor.shape(bs, 900, 25)
            anchor : Tensor.shape(bs, 900, 11)
            self.cached_feature: None or
            self.cached_anchor: None or
            time_interval: TensorShape (bs, )
        """
        instance_feature = self.instance_feature[None].repeat((batch_size, 1, 1))  # [1, 900, 256]
        anchor = self.anchor[None].repeat((batch_size, 1, 1))    # [1, 900, 11]

        if self.cached_anchor is not None and batch_size == self.cached_anchor.shape[0]:
            history_time = self.metas["timestamp"]
            time_interval = metas["timestamp"] - history_time
            time_interval = time_interval.to(dtype=instance_feature.dtype)
            self.mask = torch.abs(time_interval) <= self.max_time_interval  # < 2s

            if self.anchor_handler is not None:
                T_temp2cur = self.cached_anchor.new_tensor(
                    np.stack(
                        [
                            x["global2lidar"]
                            @ self.metas["img_metas"][i]["lidar2global"]
                            for i, x in enumerate(metas["img_metas"])   # ä¸Šä¸€å¸§æ•°æ®çš„globalåæ ‡ç³»åˆ°å½“å‰å¸§globalåæ ‡ç³»çš„æ—‹è½¬å¹³ç§»çŸ©é˜µ
                        ]
                    )
                )  # (1, 4, 4)
                self.cached_anchor = self.anchor_handler.anchor_projection(
                    self.cached_anchor,
                    [T_temp2cur],
                    time_intervals=[-time_interval],
                )[0]  # å°†ä¸Šä¸€å¸§çš„anchoræŠ•å½±è‡³å½“å‰å¸§

            if (
                self.anchor_handler is not None
                and dn_metas is not None
                and batch_size == dn_metas["dn_anchor"].shape[0]
            ):  # train mode step in
                num_dn_group, num_dn = dn_metas["dn_anchor"].shape[1:3]
                dn_anchor = self.anchor_handler.anchor_projection(
                    dn_metas["dn_anchor"].flatten(1, 2),
                    [T_temp2cur],
                    time_intervals=[-time_interval],
                )[0]
                dn_metas["dn_anchor"] = dn_anchor.reshape(
                    batch_size, num_dn_group, num_dn, -1
                )
            time_interval = torch.where(    # æœ‰æ•°æ®æ—¶ç”¨æ•°æ®çš„æ—¶é—´é—´éš”ï¼Œ æ²¡æ•°æ®æ—¶ç”¨é»˜è®¤æ—¶é—´é—´éš”
                torch.logical_and(time_interval != 0, self.mask),
                time_interval,
                time_interval.new_tensor(self.default_time_interval),
            )
        else:
            self.reset()
            time_interval = instance_feature.new_tensor(
                [self.default_time_interval] * batch_size
            )

        return (
            instance_feature,       # [1, 900, 256]
            anchor,                 # [1, 900, 11]
            self.cached_feature,    # [1, 600, 256]
            self.cached_anchor,     # [1, 600, 11]
            time_interval,
        )

    def update(self, instance_feature, anchor, confidence):
        """ "
        Args:
            instance_feature: TensorShape(bs, 1220, 256)
            anchor: TensorShape(bs, 1220, 11)
        Return:

        """
        if self.cached_feature is None:
            return instance_feature, anchor

        num_dn = 0
        if instance_feature.shape[1] > self.num_anchor:
            num_dn = instance_feature.shape[1] - self.num_anchor
            dn_instance_feature = instance_feature[:, -num_dn:]
            dn_anchor = anchor[:, -num_dn:]
            instance_feature = instance_feature[:, : self.num_anchor]
            anchor = anchor[:, : self.num_anchor]
            confidence = confidence[:, : self.num_anchor]

        N = self.num_anchor - self.num_temp_instances
        confidence = confidence.max(dim=-1).values
        
        # æ¯”è¾ƒä¸åŒtopkæ–¹æ³•çš„å·®å¼‚ï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹ï¼‰
        # if hasattr(self, 'debug_mode') and self.debug_mode:
        # print(f"\nğŸ” æ¯”è¾ƒTopKæ–¹æ³•å·®å¼‚ - ç½®ä¿¡åº¦å½¢çŠ¶: {confidence.shape}, k={N}")
        # compare_topk_methods(confidence, N, instance_feature, anchor)
        
        confidence_sorted, (selected_feature, selected_anchor), indices = topk_for_onnx_export(
            confidence, N, instance_feature, anchor
        )
        selected_feature = torch.cat([self.cached_feature, selected_feature], dim=1)
        selected_anchor = torch.cat([self.cached_anchor, selected_anchor], dim=1)

        # æ–°å¢ä¸­é—´å˜é‡
        self.selected_feature = selected_feature
        self.selected_anchor = selected_anchor
        self.confidence_sorted = confidence_sorted
        self.indices = indices
        instance_feature = torch.where(
            self.mask[:, None, None], selected_feature, instance_feature
        )
        anchor = torch.where(self.mask[:, None, None], selected_anchor, anchor)
        if self.track_id is not None:
            self.track_id = torch.where(
                self.mask[:, None],
                self.track_id,
                self.track_id.new_tensor(-1),
            )

        if num_dn > 0:
            instance_feature = torch.cat([instance_feature, dn_instance_feature], dim=1)
            anchor = torch.cat([anchor, dn_anchor], dim=1)
        return instance_feature, anchor

    def cache(
        self,
        instance_feature,
        anchor,
        confidence,
        metas=None,
        feature_maps=None,
    ):
        if self.num_temp_instances <= 0:
            return
        instance_feature = instance_feature.detach()
        anchor = anchor.detach()
        confidence = confidence.detach()

        self.metas = metas
        confidence = confidence.max(dim=-1).values.sigmoid()  # (B, num_querys)
        if self.confidence is not None:
            confidence[:, : self.num_temp_instances] = torch.maximum(
                self.confidence * self.confidence_decay,
                confidence[:, : self.num_temp_instances],
            )
        self.temp_confidence = confidence

        (
            self.confidence,
            (self.cached_feature, self.cached_anchor),
            self.temp_topk_indice,
        ) = topk(confidence, self.num_temp_instances, instance_feature, anchor)

    def get_track_id(self, confidence, threshold):
        # def get_track_id(self, confidence, anchor=None, threshold=None):
        # confidence = confidence.max(dim=-1).values.sigmoid()  # (bs, num_querys)
        track_id = confidence.new_full(confidence.shape[:2], -1).long()

        if self.track_id is not None and self.track_id.shape[0] == track_id.shape[0]:
            track_id[:, : self.track_id.shape[1]] = self.track_id

        mask = track_id < 0
        if threshold is not None:
            mask = mask & (confidence >= threshold)
        num_new_instance = mask.sum()
        new_ids = torch.arange(num_new_instance).to(track_id) + self.prev_id
        track_id[torch.where(mask)] = new_ids
        self.prev_id += num_new_instance
        # self.update_track_id(track_id, confidence)
        self.update_track_id(track_id)
        return track_id

    def update_track_id(self, track_id=None):
        # def update_track_id(self, track_id=None, confidence=None):
        # if self.temp_confidence is None:
        #     if confidence.dim() == 3:  # bs, num_anchor, num_cls
        #         temp_conf = confidence.max(dim=-1).values
        #     else:  # bs, num_anchor
        #         temp_conf = confidence
        # else:
        #     temp_conf = self.temp_confidence
        # track_id = topk(temp_conf, self.num_temp_instances, track_id)[1][0]
        # track_id = track_id.squeeze(dim=-1)  # (bs, k)

        bs = track_id.shape[0]
        track_id = track_id.flatten(end_dim=1)[self.temp_topk_indice].reshape(bs, -1)
        self.track_id = F.pad(
            track_id,
            (0, self.num_anchor - self.num_temp_instances),
            value=-1,
        )  # (bs, num_querys)


def topk_completely_stable(confidence, k, *inputs):
    """
    å®Œå…¨ç¨³å®šçš„topkå‡½æ•°ï¼Œç¡®ä¿PyTorchå’ŒTensorRTå®Œå…¨ä¸€è‡´
    
    confidence  : torch.tensor, shape(bs, num_querys)
    inputs:
        instance_feature : torch.tensor, shape(bs, num_querys, 256)
        anchor  : torch.tensor, shape(bs, num_querys, 10)
        cls     : torch.tensor, shape(bs, num_querys, 11)
    """
    batch_size = confidence.shape[0]
    results = []
    
    for b in range(batch_size):
        # 1. åˆ›å»º(confidence, index)å¯¹ï¼Œä½¿ç”¨é«˜ç²¾åº¦
        confidence_with_index = []
        for i, conf in enumerate(confidence[b]):
            # ä½¿ç”¨é«˜ç²¾åº¦æµ®ç‚¹æ•°ï¼Œé¿å…ç²¾åº¦æŸå¤±
            conf_high_precision = float(conf.item())
            confidence_with_index.append((conf_high_precision, i))
        
        # 2. ä½¿ç”¨Pythonå†…ç½®çš„ç¨³å®šæ’åºï¼Œç¡®ä¿å®Œå…¨ç¡®å®šæ€§
        # é¦–å…ˆæŒ‰confidenceé™åºæ’åºï¼Œç„¶åæŒ‰indexå‡åºæ’åºï¼ˆç¡®ä¿ç›¸åŒconfidenceå€¼çš„ç¡®å®šæ€§ï¼‰
        confidence_with_index.sort(key=lambda x: (-x[0], x[1]))
        
        # 3. æå–top-kçš„ç»“æœ
        top_k_indices = [idx for _, idx in confidence_with_index[:k]]
        top_k_confidence = [conf for conf, _ in confidence_with_index[:k]]
        
        # 4. è½¬æ¢ä¸ºtensor
        indices_b = torch.tensor(top_k_indices, device=confidence.device, dtype=torch.long)
        confidence_sorted_b = torch.tensor(top_k_confidence, device=confidence.device, dtype=torch.float32)
        
        # 5. é€‰æ‹©å¯¹åº”çš„ç‰¹å¾å’Œé”šç‚¹
        selected_feature_b = torch.gather(inputs[0][b:b+1], 1, 
                                        indices_b.unsqueeze(-1).expand(1, -1, inputs[0].shape[-1]))
        selected_anchor_b = torch.gather(inputs[1][b:b+1], 1, 
                                       indices_b.unsqueeze(-1).expand(1, -1, inputs[1].shape[-1]))
        
        results.append((confidence_sorted_b, selected_feature_b, selected_anchor_b, indices_b))
    
    # 6. åˆå¹¶batchç»“æœ
    confidence_sorted = torch.stack([r[0] for r in results])
    selected_feature = torch.cat([r[1] for r in results], dim=0)
    selected_anchor = torch.cat([r[2] for r in results], dim=0)
    indices = torch.stack([r[3] for r in results])
    
    return confidence_sorted, [selected_feature, selected_anchor], indices


def topk_with_preprocessing(confidence, k, *inputs):
    """
    å¸¦é¢„å¤„ç†çš„å®Œå…¨ç¨³å®štopkå‡½æ•°
    """
    # 1. æ•°å€¼é¢„å¤„ç†ï¼šæ ‡å‡†åŒ–å’Œå»å™ª
    confidence_clean = confidence.clone()
    
    # ç§»é™¤NaNå’ŒInf
    confidence_clean = torch.where(torch.isfinite(confidence_clean), confidence_clean, torch.zeros_like(confidence_clean))
    
    # æ·»åŠ å°çš„epsiloné¿å…å®Œå…¨ç›¸åŒçš„å€¼
    epsilon = 1e-10
    confidence_clean = confidence_clean + epsilon
    
    # 2. ä½¿ç”¨å®Œå…¨ç¨³å®šçš„æ’åº
    confidence_sorted, outputs, indices = topk_completely_stable(
        confidence_clean, k, *inputs
    )
    
    # 3. åå¤„ç†ï¼šç§»é™¤æ·»åŠ çš„epsilon
    confidence_sorted = confidence_sorted - epsilon
    
    return confidence_sorted, outputs, indices


def verify_consistency(confidence, indices, k):
    """éªŒè¯topkç»“æœçš„ä¸€è‡´æ€§"""
    # éªŒè¯indicesçš„æœ‰æ•ˆæ€§
    assert indices.min() >= 0, f"Indices must be non-negative, got {indices.min()}"
    assert indices.max() < confidence.shape[-1], f"Indices out of range, got {indices.max()}"
    
    # éªŒè¯æ²¡æœ‰é‡å¤ç´¢å¼•ï¼ˆè€ƒè™‘batchç»´åº¦ï¼‰
    total_indices = indices.numel()
    unique_indices = torch.unique(indices)
    unique_count = len(unique_indices)
    
    # å…è®¸æœ‰é‡å¤ç´¢å¼•ï¼Œä½†éœ€è¦æ£€æŸ¥æ˜¯å¦åˆç†
    if unique_count < total_indices:
        print(f"âš ï¸  Warning: Found {total_indices - unique_count} duplicate indices")
        print(f"   Total indices: {total_indices}, Unique indices: {unique_count}")
        
        # æ£€æŸ¥æ¯ä¸ªbatchå†…çš„é‡å¤æƒ…å†µ
        if indices.dim() == 2:  # (batch_size, k)
            for b in range(indices.shape[0]):
                batch_indices = indices[b]
                batch_unique = torch.unique(batch_indices)
                batch_duplicates = len(batch_indices) - len(batch_unique)
                if batch_duplicates > 0:
                    print(f"   Batch {b}: {batch_duplicates} duplicates")
    
    # éªŒè¯confidenceçš„æ’åºæ­£ç¡®æ€§
    try:
        selected_confidence = torch.gather(confidence, 1, indices)
        # æ£€æŸ¥æ¯ä¸ªbatchå†…çš„æ’åº
        for b in range(selected_confidence.shape[0]):
            batch_conf = selected_confidence[b]
            if not torch.all(batch_conf[:-1] >= batch_conf[1:]):
                print(f"âš ï¸  Warning: Confidence not properly sorted in batch {b}")
                print(f"   First few values: {batch_conf[:5]}")
    except Exception as e:
        print(f"âš ï¸  Warning: Could not verify confidence sorting: {e}")
    
    print("âœ… TopK consistency verification passed")
    return True


def topk_onnx_compatible(confidence, k, *inputs):
    """
    ONNXå…¼å®¹çš„topkå‡½æ•°ï¼Œé¿å…TracerWarningå’ŒIsInfæ“ä½œ
    
    è¿™ä¸ªå‡½æ•°ä½¿ç”¨çº¯PyTorchæ“ä½œï¼Œç¡®ä¿ONNXå¯¼å‡ºæ—¶ä¸ä¼šäº§ç”Ÿè­¦å‘Š
    """
    bs, N = confidence.shape[:2]
    
    # 1. æ•°å€¼é¢„å¤„ç†ï¼šä½¿ç”¨ONNXå…¼å®¹çš„æ“ä½œ
    confidence_clean = confidence.clone()
    
    # ä½¿ç”¨ç®€å•çš„clampæ“ä½œæ›¿ä»£isfiniteï¼Œé¿å…IsInf
    # å°†å¼‚å¸¸å€¼é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
    confidence_clean = torch.clamp(confidence_clean, -1e6, 1e6)
    
    # æ·»åŠ å°çš„epsiloné¿å…å®Œå…¨ç›¸åŒçš„å€¼
    epsilon = 1e-10
    confidence_clean = confidence_clean + epsilon
    
    # 2. ä½¿ç”¨torch.topkè¿›è¡Œæ’åºï¼ˆONNXå…¼å®¹ï¼‰
    # æ·»åŠ ä½ç½®æƒé‡ç¡®ä¿æ’åºçš„ç¡®å®šæ€§
    position_indices = torch.arange(N, device=confidence.device, dtype=torch.float32)
    position_indices = position_indices.unsqueeze(0).expand(bs, -1)
    
    # ä½¿ç”¨å¾ˆå°çš„æƒé‡ç¡®ä¿ä½ç½®ç´¢å¼•ä¸å½±å“ä¸»è¦æ’åºï¼Œä½†èƒ½ä¿è¯ç¡®å®šæ€§
    position_weight = 1e-8
    stable_confidence = confidence_clean + position_weight * position_indices
    
    # 3. æ‰§è¡Œtopkæ“ä½œ
    confidence_sorted, indices = torch.topk(stable_confidence, k, dim=1)
    
    # 4. åå¤„ç†ï¼šç§»é™¤æ·»åŠ çš„epsilonå’Œä½ç½®æƒé‡
    confidence_sorted = confidence_sorted - epsilon - position_weight * indices
    
    # 5. é€‰æ‹©å¯¹åº”çš„ç‰¹å¾å’Œé”šç‚¹
    outputs = []
    for input_tensor in inputs:
        # ä½¿ç”¨gatheræ“ä½œï¼ŒONNXå…¼å®¹
        selected = torch.gather(input_tensor, 1, indices.unsqueeze(-1).expand(-1, -1, input_tensor.size(-1)))
        outputs.append(selected)
    
    return confidence_sorted, outputs, indices


def topk_onnx_compatiblev2(confidence, k, *inputs):
    """
    ONNXå…¼å®¹çš„topkå‡½æ•°ï¼Œé¿å…TracerWarningå’ŒIsInfæ“ä½œ
    
    è¿™ä¸ªå‡½æ•°ä½¿ç”¨çº¯PyTorchæ“ä½œï¼Œç¡®ä¿ONNXå¯¼å‡ºæ—¶ä¸ä¼šäº§ç”Ÿè­¦å‘Š
    """
    
    # æ·»åŠ å°çš„epsiloné¿å…å®Œå…¨ç›¸åŒçš„å€¼
    delta = torch.arange(confidence.shape[1], 
		device=confidence.device,dtype=confidence.dtype) * (1e-5 * confidence.std())
    confidence = confidence + delta
    
    # 3. æ‰§è¡Œtopkæ“ä½œ
    confidence_sorted, indices = torch.topk(confidence, k, dim=1)
    
    # 5. é€‰æ‹©å¯¹åº”çš„ç‰¹å¾å’Œé”šç‚¹
    outputs = []
    for input_tensor in inputs:
        # ä½¿ç”¨gatheræ“ä½œï¼ŒONNXå…¼å®¹
        selected = torch.gather(input_tensor, 1, indices.unsqueeze(-1).expand(-1, -1, input_tensor.size(-1)))
        outputs.append(selected)
    
    return confidence_sorted, outputs, indices


def topk_for_onnx_export(confidence, k, *inputs):
    """
    ä¸“é—¨ç”¨äºONNXå¯¼å‡ºçš„topkå‡½æ•°
    
    ä½¿ç”¨è‡ªå®šä¹‰Sortå®ç°ï¼Œç¡®ä¿ONNXå…¼å®¹æ€§å’Œæ’åºç¨³å®šæ€§
    """
    
    # ä½¿ç”¨è‡ªå®šä¹‰Sortå®ç°çš„ç¨³å®štopk
    return topk(confidence, k, *inputs)