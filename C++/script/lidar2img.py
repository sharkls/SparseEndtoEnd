#!/usr/bin/env python3
"""
æ¿€å…‰é›·è¾¾ç‚¹äº‘æŠ•å½±åˆ°ç›¸æœºå›¾åƒçš„å¯è§†åŒ–è„šæœ¬
åŸºäºlidar2imgå˜æ¢çŸ©é˜µå°†3Dç‚¹äº‘æŠ•å½±åˆ°2Då›¾åƒå¹³é¢
æ”¯æŒå¤šç›¸æœºæ•°æ®ç»“æ„ï¼Œä»nuScenesæ•°æ®é›†ç›´æ¥è®¡ç®—lidar2imgå˜æ¢çŸ©é˜µ
"""

import numpy as np
import cv2
import os
import struct
import matplotlib.pyplot as plt
from pathlib import Path
import argparse
import json
from tqdm import tqdm

def load_lidar_points(lidar_path):
    """åŠ è½½æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®"""
    with open(lidar_path, 'rb') as f:
        data = f.read()
    
    # å‡è®¾æ¯ä¸ªç‚¹æœ‰5ä¸ªfloatå€¼ (x, y, z, intensity, ring)
    num_points = len(data) // (5 * 4)  # 5ä¸ªfloatï¼Œæ¯ä¸ª4å­—èŠ‚
    points = np.frombuffer(data, dtype=np.float32).reshape(-1, 5)
    
    return points[:, :3]  # åªè¿”å›x, y, zåæ ‡

def debug_calibration_matrix(matrix, camera_name):
    """è°ƒè¯•æ ‡å®šçŸ©é˜µ"""
    print(f"    ğŸ” {camera_name} æ ‡å®šçŸ©é˜µè°ƒè¯•ä¿¡æ¯:")
    print(f"      çŸ©é˜µå½¢çŠ¶: {matrix.shape}")
    print(f"      çŸ©é˜µå†…å®¹:")
    print(f"        {matrix}")
    
    # åˆ†æå†…å‚éƒ¨åˆ†
    fx = matrix[0, 0]
    fy = matrix[1, 1]
    cx = matrix[0, 2]
    cy = matrix[1, 2]
    
    print(f"      å†…å‚åˆ†æ:")
    print(f"        ç„¦è· fx: {fx:.1f}")
    print(f"        ç„¦è· fy: {fy:.1f}")
    print(f"        ä¸»ç‚¹ cx: {cx:.1f}")
    print(f"        ä¸»ç‚¹ cy: {cy:.1f}")
    
    # åˆ†æå¤–å‚éƒ¨åˆ†
    tx = matrix[0, 3]
    ty = matrix[1, 3]
    tz = matrix[2, 3]
    
    print(f"      å¤–å‚åˆ†æ:")
    print(f"        å¹³ç§» x: {tx:.3f}")
    print(f"        å¹³ç§» y: {ty:.3f}")
    print(f"        å¹³ç§» z: {tz:.3f}")
    
    # æ£€æŸ¥çŸ©é˜µæ˜¯å¦åˆç†
    if fx <= 0 or fy <= 0:
        print(f"      âŒ ç„¦è·å€¼å¼‚å¸¸: fx={fx}, fy={fy}")
    
    if abs(cx) > 2000 or abs(cy) > 2000:
        print(f"      âŒ ä¸»ç‚¹å€¼å¼‚å¸¸: cx={cx}, cy={cy}")
    
    if abs(tx) > 100 or abs(ty) > 100 or abs(tz) > 100:
        print(f"      âŒ å¹³ç§»å€¼å¼‚å¸¸: tx={tx}, ty={ty}, tz={tz}")

def load_lidar2img_matrix(calib_path, camera_index=0):
    """åŠ è½½lidar2imgå˜æ¢çŸ©é˜µ
    
    Args:
        calib_path: æ ‡å®šæ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«6ä¸ªç›¸æœºçš„å˜æ¢çŸ©é˜µï¼‰
        camera_index: ç›¸æœºç´¢å¼• (0-5ï¼Œå¯¹åº”6ä¸ªç›¸æœº)
    """
    with open(calib_path, 'rb') as f:
        data = f.read()
    
    # è®¡ç®—æ¯ä¸ªçŸ©é˜µçš„å¤§å°
    total_size = len(data)
    num_cameras = 6  # 6ä¸ªç›¸æœº
    matrix_size = 4 * 4 * 4  # 4x4çŸ©é˜µï¼Œæ¯ä¸ªå…ƒç´ 4å­—èŠ‚float
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦åˆç†
    expected_size = num_cameras * matrix_size
    if total_size != expected_size:
        print(f"è­¦å‘Š: æ ‡å®šæ–‡ä»¶å¤§å°ä¸åŒ¹é…ã€‚æœŸæœ› {expected_size} å­—èŠ‚ï¼Œå®é™… {total_size} å­—èŠ‚")
        # å°è¯•è¯»å–å•ä¸ª4x4çŸ©é˜µ
        if total_size >= matrix_size:
            matrix = np.frombuffer(data[:matrix_size], dtype=np.float32).reshape(4, 4)
            return matrix
        else:
            # è¿”å›å•ä½çŸ©é˜µä½œä¸ºé»˜è®¤å€¼
            return np.eye(4, dtype=np.float32)
    
    # è¯»å–æŒ‡å®šç›¸æœºçš„å˜æ¢çŸ©é˜µ
    start_offset = camera_index * matrix_size
    end_offset = start_offset + matrix_size
    
    if start_offset >= total_size:
        print(f"è­¦å‘Š: ç›¸æœºç´¢å¼• {camera_index} è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨å•ä½çŸ©é˜µ")
        return np.eye(4, dtype=np.float32)
    
    matrix_data = data[start_offset:end_offset]
    matrix = np.frombuffer(matrix_data, dtype=np.float32).reshape(4, 4)
    
    return matrix

def load_image(image_path):
    """åŠ è½½å›¾åƒ"""
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")
    return img

def project_lidar_to_image(points_3d, lidar2img_matrix, img_shape):
    """å°†3Dç‚¹äº‘æŠ•å½±åˆ°2Då›¾åƒå¹³é¢"""
    # æ·»åŠ é½æ¬¡åæ ‡
    points_homo = np.hstack([points_3d, np.ones((points_3d.shape[0], 1))])
    
    # åº”ç”¨å˜æ¢çŸ©é˜µ
    points_cam = points_homo @ lidar2img_matrix.T
    
    # é€è§†é™¤æ³•
    points_cam[:, 0] /= points_cam[:, 2]
    points_cam[:, 1] /= points_cam[:, 2]
    
    # æå–2Dåæ ‡
    points_2d = points_cam[:, :2]
    
    # è¿‡æ»¤åœ¨å›¾åƒèŒƒå›´å†…çš„ç‚¹
    mask = (points_2d[:, 0] >= 0) & (points_2d[:, 0] < img_shape[1]) & \
           (points_2d[:, 1] >= 0) & (points_2d[:, 1] < img_shape[0]) & \
           (points_cam[:, 2] > 0)  # æ·±åº¦ä¸ºæ­£
    
    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
    if len(points_2d) > 0:
        print(f"    æŠ•å½±ç»Ÿè®¡:")
        print(f"      æ€»ç‚¹æ•°: {len(points_3d)}")
        print(f"      æœ‰æ•ˆæŠ•å½±ç‚¹æ•°: {np.sum(mask)}")
        print(f"      XèŒƒå›´: [{points_2d[:, 0].min():.1f}, {points_2d[:, 0].max():.1f}]")
        print(f"      YèŒƒå›´: [{points_2d[:, 1].min():.1f}, {points_2d[:, 1].max():.1f}]")
        print(f"      æ·±åº¦èŒƒå›´: [{points_cam[:, 2].min():.1f}, {points_cam[:, 2].max():.1f}]")
        
        # æ£€æŸ¥æŠ•å½±ç‚¹æ˜¯å¦é›†ä¸­åœ¨æŸä¸ªåŒºåŸŸ
        if np.sum(mask) > 0:
            valid_points = points_2d[mask]
            x_std = np.std(valid_points[:, 0])
            y_std = np.std(valid_points[:, 1])
            print(f"      Xæ ‡å‡†å·®: {x_std:.1f}, Yæ ‡å‡†å·®: {y_std:.1f}")
            
            if x_std < 50 or y_std < 50:
                print(f"      âš ï¸ è­¦å‘Š: æŠ•å½±ç‚¹åˆ†å¸ƒè¿‡äºé›†ä¸­ï¼Œå¯èƒ½æ ‡å®šçŸ©é˜µæœ‰é—®é¢˜")
    
    return points_2d[mask], mask

def create_color_map(depths, color_map_name='jet'):
    """æ ¹æ®æ·±åº¦åˆ›å»ºé¢œè‰²æ˜ å°„"""
    # å½’ä¸€åŒ–æ·±åº¦åˆ°0-1
    depths_norm = (depths - depths.min()) / (depths.max() - depths.min() + 1e-6)
    
    # ä½¿ç”¨æŒ‡å®šçš„é¢œè‰²æ˜ å°„
    cmap = plt.get_cmap(color_map_name)
    colors = cmap(depths_norm)[:, :3] * 255
    return colors.astype(np.uint8)

def generate_lidar2img_from_nuscenes(config_path, output_dir, num_frames=10):
    """
    ä»nuScenesæ•°æ®é›†ç”Ÿæˆlidar2imgå˜æ¢çŸ©é˜µï¼Œæ¯å¸§å•ç‹¬ä¿å­˜ä¸ºä¸€ä¸ªbinæ–‡ä»¶
    
    Args:
        config_path: æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        num_frames: è¦ç”Ÿæˆçš„å¸§æ•°
    """
    print(f"ä»nuScenesæ•°æ®é›†ç”Ÿæˆlidar2imgå˜æ¢çŸ©é˜µï¼Œå…±{num_frames}å¸§...")
    
    try:
        from nuscenes import NuScenes
        from pyquaternion import Quaternion
    except ImportError as e:
        print(f"âŒ nuScenesæˆ–pyquaternionæœªå®‰è£…: {e}")
        print("è¯·å®‰è£…: pip install nuscenes-devkit pyquaternion")
        return False
    
    # è¯»å–é…ç½®
    try:
        from tool.utils.config import read_cfg
        cfg = read_cfg(config_path)
        dataset_cfg = cfg["data"]["val"].copy()
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–é…ç½®æ–‡ä»¶: {e}")
        return False
    
    # è·å–nuScenesæ•°æ®é›†è·¯å¾„
    data_root = dataset_cfg.get("data_root", "")
    version = dataset_cfg.get("version", "v1.0-trainval")
    
    print(f"æ•°æ®æ ¹ç›®å½•: {data_root}")
    print(f"æ•°æ®é›†ç‰ˆæœ¬: {version}")
    
    if not data_root or not os.path.exists(data_root):
        print(f"âŒ æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {data_root}")
        return False
    
    try:
        # åˆå§‹åŒ–nuScenes
        nusc = NuScenes(version=version, dataroot=data_root, verbose=False)
        print(f"âœ… NuScenesåŠ è½½æˆåŠŸï¼Œå…±{len(nusc.sample)}ä¸ªæ ·æœ¬")
    except Exception as e:
        print(f"âŒ åŠ è½½NuSceneså¤±è´¥: {e}")
        return False
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    calib_dir = os.path.join(output_dir, "calib")
    os.makedirs(calib_dir, exist_ok=True)
    
    # ç›¸æœºç±»å‹åˆ—è¡¨
    camera_types = ["CAM_FRONT", "CAM_FRONT_RIGHT", "CAM_FRONT_LEFT", 
                   "CAM_BACK", "CAM_BACK_LEFT", "CAM_BACK_RIGHT"]
    
    # è·å–æ‰€æœ‰æ ·æœ¬
    samples = list(nusc.sample)
    print(f"æ‰¾åˆ°{len(samples)}ä¸ªæ ·æœ¬")
    
    # å¤„ç†å‰num_framesä¸ªæ ·æœ¬
    for frame_idx in tqdm(range(min(num_frames, len(samples))), desc="ç”Ÿæˆlidar2imgçŸ©é˜µ"):
        sample = samples[frame_idx]
        
        try:
            # è·å–æ¿€å…‰é›·è¾¾çš„æ ‡å®šä¿¡æ¯
            lidar_data = nusc.get('sample_data', sample['data']['LIDAR_TOP'])
            lidar_sensor = nusc.get('calibrated_sensor', lidar_data['calibrated_sensor_token'])
            lidar_pose = nusc.get('ego_pose', lidar_data['ego_pose_token'])
            
            # ä¸ºæ¯ä¸ªç›¸æœºæ„å»ºlidar2imgå˜æ¢çŸ©é˜µ
            all_lidar2img_matrices = []
            
            for cam_type in camera_types:
                if cam_type in sample['data']:
                    cam_data = nusc.get('sample_data', sample['data'][cam_type])
                    
                    try:
                        # è·å–ç›¸æœºæ ‡å®šä¿¡æ¯
                        cam_sensor = nusc.get('calibrated_sensor', cam_data['calibrated_sensor_token'])
                        cam_pose = nusc.get('ego_pose', cam_data['ego_pose_token'])
                        
                        # æ„å»ºå®Œæ•´çš„å˜æ¢çŸ©é˜µé“¾
                        # 1. æ¿€å…‰é›·è¾¾åˆ°egoçš„å˜æ¢
                        lidar2ego_R = Quaternion(lidar_sensor['rotation']).rotation_matrix
                        lidar2ego_T = np.array(lidar_sensor['translation'])
                        lidar2ego = np.eye(4)
                        lidar2ego[:3, :3] = lidar2ego_R
                        lidar2ego[:3, 3] = lidar2ego_T
                        
                        # 2. egoåˆ°globalçš„å˜æ¢ï¼ˆæ¿€å…‰é›·è¾¾å¸§ï¼‰
                        ego2global_R = Quaternion(lidar_pose['rotation']).rotation_matrix
                        ego2global_T = np.array(lidar_pose['translation'])
                        ego2global = np.eye(4)
                        ego2global[:3, :3] = ego2global_R
                        ego2global[:3, 3] = ego2global_T
                        
                        # 3. globalåˆ°egoçš„å˜æ¢ï¼ˆç›¸æœºå¸§ï¼‰
                        cam_ego2global_R = Quaternion(cam_pose['rotation']).rotation_matrix
                        cam_ego2global_T = np.array(cam_pose['translation'])
                        cam_ego2global = np.eye(4)
                        cam_ego2global[:3, :3] = cam_ego2global_R
                        cam_ego2global[:3, 3] = cam_ego2global_T
                        
                        # è®¡ç®—globalåˆ°egoçš„é€†å˜æ¢
                        global2cam_ego = np.linalg.inv(cam_ego2global)
                        
                        # 4. egoåˆ°ç›¸æœºçš„å˜æ¢
                        cam2ego_R = Quaternion(cam_sensor['rotation']).rotation_matrix
                        cam2ego_T = np.array(cam_sensor['translation'])
                        cam2ego = np.eye(4)
                        cam2ego[:3, :3] = cam2ego_R
                        cam2ego[:3, 3] = cam2ego_T
                        
                        # è®¡ç®—egoåˆ°ç›¸æœºçš„é€†å˜æ¢
                        ego2cam = np.linalg.inv(cam2ego)
                        
                        # 5. ç›¸æœºå†…å‚çŸ©é˜µ
                        cam_intrinsic = np.array(cam_sensor['camera_intrinsic'])
                        intrinsic_4x4 = np.eye(4)
                        intrinsic_4x4[:3, :3] = cam_intrinsic
                        
                        # ç»„åˆå˜æ¢çŸ©é˜µï¼šlidar -> ego -> global -> ego' -> camera -> image
                        lidar2img_4x4 = intrinsic_4x4 @ ego2cam @ global2cam_ego @ ego2global @ lidar2ego
                        
                    except Exception as e:
                        print(f"    âš ï¸ è®¡ç®—{cam_type}çš„ç²¾ç¡®å˜æ¢æ—¶å‡ºé”™: {e}")
                        # ä½¿ç”¨åˆç†çš„é»˜è®¤å˜æ¢çŸ©é˜µ
                        lidar2img_4x4 = np.eye(4)
                        
                        # è®¾ç½®ç›¸æœºå†…å‚ï¼ˆåŸºäºnuScenesçš„å…¸å‹å€¼ï¼‰
                        lidar2img_4x4[0, 0] = 1200.0  # fx - ç„¦è·x
                        lidar2img_4x4[1, 1] = 1200.0  # fy - ç„¦è·y
                        lidar2img_4x4[0, 2] = 800.0   # cx - ä¸»ç‚¹x (1600/2)
                        lidar2img_4x4[1, 2] = 450.0   # cy - ä¸»ç‚¹y (900/2)
                        
                        # è®¾ç½®å¤–å‚ï¼ˆæ¿€å…‰é›·è¾¾åˆ°ç›¸æœºçš„å˜æ¢ï¼‰
                        lidar2img_4x4[0, 3] = 0.0     # xåç§»
                        lidar2img_4x4[1, 3] = 0.0     # yåç§»
                        lidar2img_4x4[2, 3] = -1.5    # zåç§»ï¼ˆæ¿€å…‰é›·è¾¾åˆ°ç›¸æœºçš„é«˜åº¦å·®ï¼‰
                    
                    all_lidar2img_matrices.append(lidar2img_4x4)
                else:
                    # å¦‚æœç›¸æœºæ•°æ®ä¸å­˜åœ¨ï¼Œä½¿ç”¨å•ä½çŸ©é˜µ
                    all_lidar2img_matrices.append(np.eye(4))
            
            # å°†6ä¸ªç›¸æœºçš„å˜æ¢çŸ©é˜µä¿å­˜åˆ°ä¸€ä¸ªæ–‡ä»¶ä¸­
            calib_path = os.path.join(calib_dir, f"lidar2img_{frame_idx}.bin")
            all_matrices = np.array(all_lidar2img_matrices, dtype=np.float32)
            all_matrices.tofile(calib_path)
            
            print(f"å¸§ {frame_idx}: ä¿å­˜äº†{len(all_lidar2img_matrices)}ä¸ªç›¸æœºçš„æ ‡å®šæ•°æ®åˆ° {calib_path}")
            
        except Exception as e:
            print(f"å¤„ç†å¸§ {frame_idx} æ—¶å‡ºé”™: {e}")
            continue
    
    print(f"âœ… æˆåŠŸç”Ÿæˆ{min(num_frames, len(samples))}å¸§çš„lidar2imgå˜æ¢çŸ©é˜µ")
    return True

def visualize_projection(frame_idx, data_dir, output_dir, cameras, point_size=1, alpha=0.6, color_map='jet', debug=False):
    """å¯è§†åŒ–å•å¸§çš„æŠ•å½±ç»“æœ"""
    print(f"å¤„ç†å¸§ {frame_idx}...")
    
    # åŠ è½½æ¿€å…‰é›·è¾¾ç‚¹äº‘
    lidar_path = os.path.join(data_dir, 'lidar', f'lidar_{frame_idx}.bin')
    if not os.path.exists(lidar_path):
        print(f"æ¿€å…‰é›·è¾¾æ–‡ä»¶ä¸å­˜åœ¨: {lidar_path}")
        return
    
    points_3d = load_lidar_points(lidar_path)
    print(f"åŠ è½½äº† {len(points_3d)} ä¸ªæ¿€å…‰é›·è¾¾ç‚¹")
    
    # åˆ›å»ºå¤§å›¾ç”¨äºæ˜¾ç¤ºæ‰€æœ‰ç›¸æœºçš„ç»“æœ
    num_cams = len(cameras)
    cols = min(3, num_cams)
    rows = (num_cams + cols - 1) // cols
    fig, axes = plt.subplots(rows, cols, figsize=(6*cols, 4*rows))
    
    if num_cams == 1:
        axes = [axes]
    elif rows == 1:
        axes = axes
    else:
        axes = axes.flatten()
    
    for cam_idx, camera in enumerate(cameras):
        # åŠ è½½å›¾åƒ
        img_path = os.path.join(data_dir, 'images', camera, f'{frame_idx}.jpg')
        if not os.path.exists(img_path):
            print(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
            continue
        
        img = load_image(img_path)
        print(f"  ç›¸æœº {camera}: å›¾åƒå°ºå¯¸ {img.shape}")
        
        # åŠ è½½å¯¹åº”çš„lidar2imgå˜æ¢çŸ©é˜µ
        calib_path = os.path.join(data_dir, 'calib', f'lidar2img_{frame_idx}.bin')
        if not os.path.exists(calib_path):
            print(f"æ ‡å®šæ–‡ä»¶ä¸å­˜åœ¨: {calib_path}")
            continue
        
        lidar2img_matrix = load_lidar2img_matrix(calib_path, cam_idx)
        
        # è°ƒè¯•æ ‡å®šçŸ©é˜µ
        if debug:
            debug_calibration_matrix(lidar2img_matrix, camera)
        
        # æŠ•å½±ç‚¹äº‘åˆ°å›¾åƒ
        points_2d, mask = project_lidar_to_image(points_3d, lidar2img_matrix, img.shape)
        
        if len(points_2d) == 0:
            print(f"ç›¸æœº {camera} æ²¡æœ‰æŠ•å½±ç‚¹")
            continue
        
        # è·å–æ·±åº¦ä¿¡æ¯ç”¨äºé¢œè‰²æ˜ å°„
        depths = points_3d[mask, 2]  # zåæ ‡ä½œä¸ºæ·±åº¦
        colors = create_color_map(depths, color_map)
        
        # ç»˜åˆ¶æŠ•å½±ç»“æœ
        ax = axes[cam_idx]
        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        
        # ç»˜åˆ¶æŠ•å½±ç‚¹
        ax.scatter(points_2d[:, 0], points_2d[:, 1], c=colors/255, s=point_size, alpha=alpha)
        
        ax.set_title(f'{camera} - {len(points_2d)} points')
        ax.axis('off')
        
        # ä¿å­˜å•ä¸ªç›¸æœºçš„ç»“æœ
        single_img = img.copy()
        for i, (point, color) in enumerate(zip(points_2d, colors)):
            cv2.circle(single_img, (int(point[0]), int(point[1])), point_size, color.tolist(), -1)
        
        single_output_path = os.path.join(output_dir, f'frame_{frame_idx}_{camera}.jpg')
        cv2.imwrite(single_output_path, single_img)
        
        print(f"  ç›¸æœº {camera}: æŠ•å½±äº† {len(points_2d)} ä¸ªç‚¹ï¼Œä¿å­˜åˆ° {single_output_path}")
    
    # éšè—å¤šä½™çš„å­å›¾
    for i in range(num_cams, len(axes)):
        axes[i].axis('off')
    
    # ä¿å­˜ç»„åˆå›¾
    plt.tight_layout()
    combined_output_path = os.path.join(output_dir, f'frame_{frame_idx}_all_cameras.png')
    plt.savefig(combined_output_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"å¸§ {frame_idx} å¤„ç†å®Œæˆï¼Œç»“æœä¿å­˜åˆ° {output_dir}")

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description='æ¿€å…‰é›·è¾¾ç‚¹äº‘æŠ•å½±åˆ°ç›¸æœºå›¾åƒå¯è§†åŒ–')
    
    # æ•°æ®è·¯å¾„å‚æ•°
    parser.add_argument('--data_dir', type=str, 
                       default="/share/Code/SparseEnd2End/C++/Data/sparse",
                       help='æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--output_dir', type=str,
                       default="/share/Code/SparseEnd2End/C++/Output/val",
                       help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--config_path', type=str,
                       default="dataset/config/sparse4d_temporal_r50_1x1_bs1_256x704_mini.py",
                       help='nuScenesæ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„')
    
    # å¤„ç†å‚æ•°
    parser.add_argument('--frames', type=str, default='all',
                       help='è¦å¤„ç†çš„å¸§ï¼Œæ ¼å¼: "0,1,2" æˆ– "all" è¡¨ç¤ºæ‰€æœ‰å¸§')
    parser.add_argument('--cameras', type=str, default='all',
                       help='è¦å¤„ç†çš„ç›¸æœºï¼Œæ ¼å¼: "CAM_FRONT,CAM_BACK" æˆ– "all" è¡¨ç¤ºæ‰€æœ‰ç›¸æœº')
    parser.add_argument('--generate_calib', action='store_true',
                       help='æ˜¯å¦ä»nuScenesæ•°æ®é›†ç”Ÿæˆlidar2imgæ ‡å®šæ–‡ä»¶')
    parser.add_argument('--num_frames', type=int, default=10,
                       help='ç”Ÿæˆæ ‡å®šæ–‡ä»¶æ—¶çš„å¸§æ•°')
    
    # å¯è§†åŒ–å‚æ•°
    parser.add_argument('--point_size', type=int, default=1,
                       help='æŠ•å½±ç‚¹çš„å¤§å°')
    parser.add_argument('--alpha', type=float, default=0.6,
                       help='æŠ•å½±ç‚¹çš„é€æ˜åº¦ (0-1)')
    parser.add_argument('--color_map', type=str, default='jet',
                       help='æ·±åº¦é¢œè‰²æ˜ å°„ (jet, viridis, plasma, etc.)')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--create_report', action='store_true',
                       help='æ˜¯å¦åˆ›å»ºHTMLå¯è§†åŒ–æŠ¥å‘Š')
    parser.add_argument('--verbose', action='store_true',
                       help='æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º')
    parser.add_argument('--debug', action='store_true',
                       help='æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯')
    
    # è§£æå‚æ•°
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # å¦‚æœéœ€è¦ç”Ÿæˆæ ‡å®šæ–‡ä»¶
    if args.generate_calib:
        print("å¼€å§‹ä»nuScenesæ•°æ®é›†ç”Ÿæˆlidar2imgæ ‡å®šæ–‡ä»¶...")
        success = generate_lidar2img_from_nuscenes(args.config_path, args.data_dir, args.num_frames)
        if not success:
            print("âŒ ç”Ÿæˆæ ‡å®šæ–‡ä»¶å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
            return
        print("âœ… æ ‡å®šæ–‡ä»¶ç”Ÿæˆå®Œæˆ")
    
    # ç¡®å®šè¦å¤„ç†çš„ç›¸æœº
    all_cameras = ['CAM_FRONT', 'CAM_FRONT_LEFT', 'CAM_FRONT_RIGHT', 
                   'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']
    
    if args.cameras.lower() == 'all':
        cameras = all_cameras
    else:
        cameras = [cam.strip() for cam in args.cameras.split(',')]
        # éªŒè¯ç›¸æœºåç§°
        for cam in cameras:
            if cam not in all_cameras:
                print(f"è­¦å‘Š: æœªçŸ¥ç›¸æœºåç§° {cam}")
    
    # è·å–æ‰€æœ‰å¸§
    lidar_dir = os.path.join(args.data_dir, 'lidar')
    if not os.path.exists(lidar_dir):
        print(f"æ¿€å…‰é›·è¾¾ç›®å½•ä¸å­˜åœ¨: {lidar_dir}")
        return
    
    # è·å–æ‰€æœ‰å¸§ç´¢å¼•
    frame_indices = []
    for file in os.listdir(lidar_dir):
        if file.startswith('lidar_') and file.endswith('.bin'):
            frame_idx = int(file.split('_')[1].split('.')[0])
            frame_indices.append(frame_idx)
    
    frame_indices.sort()
    
    # ç¡®å®šè¦å¤„ç†çš„å¸§
    if args.frames.lower() == 'all':
        frames_to_process = frame_indices
    else:
        frames_to_process = [int(f.strip()) for f in args.frames.split(',')]
        # éªŒè¯å¸§ç´¢å¼•
        for frame_idx in frames_to_process:
            if frame_idx not in frame_indices:
                print(f"è­¦å‘Š: å¸§ {frame_idx} ä¸å­˜åœ¨")
    
    if args.verbose:
        print(f"æ•°æ®ç›®å½•: {args.data_dir}")
        print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
        print(f"è¦å¤„ç†çš„å¸§: {frames_to_process}")
        print(f"è¦å¤„ç†çš„ç›¸æœº: {cameras}")
        print(f"ç‚¹å¤§å°: {args.point_size}")
        print(f"é€æ˜åº¦: {args.alpha}")
        print(f"é¢œè‰²æ˜ å°„: {args.color_map}")
        print(f"è°ƒè¯•æ¨¡å¼: {args.debug}")
    
    print(f"æ‰¾åˆ° {len(frame_indices)} å¸§æ•°æ®ï¼Œå°†å¤„ç† {len(frames_to_process)} å¸§")
    
    # å¤„ç†æ¯ä¸€å¸§
    for frame_idx in frames_to_process:
        try:
            visualize_projection(frame_idx, args.data_dir, args.output_dir, 
                               cameras, args.point_size, args.alpha, args.color_map, args.debug)
        except Exception as e:
            print(f"å¤„ç†å¸§ {frame_idx} æ—¶å‡ºé”™: {e}")
            continue
    
    print(f"æ‰€æœ‰å¸§å¤„ç†å®Œæˆï¼Œç»“æœä¿å­˜åœ¨: {args.output_dir}")
    
    # åˆ›å»ºå¯è§†åŒ–æŠ¥å‘Š
    if args.create_report:
        create_visualization_report(args.output_dir, frames_to_process, cameras)

def create_visualization_report(output_dir, frame_indices, cameras):
    """åˆ›å»ºå¯è§†åŒ–æŠ¥å‘Š"""
    report_path = os.path.join(output_dir, 'visualization_report.html')
    
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>æ¿€å…‰é›·è¾¾æŠ•å½±å¯è§†åŒ–æŠ¥å‘Š</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; }}
            .frame {{ margin-bottom: 30px; border: 1px solid #ccc; padding: 15px; }}
            .frame h3 {{ color: #333; }}
            .camera-grid {{ display: grid; grid-template-columns: repeat(3, 1fr); gap: 10px; }}
            .camera-item {{ text-align: center; }}
            .camera-item img {{ max-width: 100%; height: auto; }}
            .camera-item p {{ margin: 5px 0; font-size: 12px; }}
            .summary {{ background-color: #f5f5f5; padding: 15px; margin-bottom: 20px; }}
        </style>
    </head>
    <body>
        <h1>æ¿€å…‰é›·è¾¾æŠ•å½±å¯è§†åŒ–æŠ¥å‘Š</h1>
        <div class="summary">
            <h3>å¤„ç†æ‘˜è¦</h3>
            <p>å¤„ç†äº† {len(frame_indices)} å¸§æ•°æ®</p>
            <p>å¤„ç†çš„ç›¸æœº: {', '.join(cameras)}</p>
            <p>è¾“å‡ºç›®å½•: {output_dir}</p>
        </div>
    """
    
    for frame_idx in frame_indices:
        html_content += f"""
        <div class="frame">
            <h3>å¸§ {frame_idx}</h3>
            <div class="camera-grid">
        """
        
        for camera in cameras:
            img_path = f'frame_{frame_idx}_{camera}.jpg'
            if os.path.exists(os.path.join(output_dir, img_path)):
                html_content += f"""
                <div class="camera-item">
                    <img src="{img_path}" alt="{camera}">
                    <p>{camera}</p>
                </div>
                """
        
        html_content += """
            </div>
        </div>
        """
    
    html_content += """
    </body>
    </html>
    """
    
    with open(report_path, 'w') as f:
        f.write(html_content)
    
    print(f"å¯è§†åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

if __name__ == "__main__":
    main()
